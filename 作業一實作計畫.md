# 實作計畫

## 注意事項
1. 實作時注意程式碼模組化並提升可重用性、可讀性
2. 在Readme.md中記錄實作的內容，以及進行各種實驗的參數、結果紀錄。進行分析與比較
3. 圖片另開一個資料夾分門別類的儲存
4. 可使用GridSearchCV進行網格化最佳超參數搜索
5. Readme中加入程式架構描述


## 選擇的分類器
1. 支持向量機(Support Vector Machine, SVM)
2. 隨機森林(Random Forest)
3. K-近鄰演算法(K-Nearest Neighbors, KNN)

## 選擇的Dataset
### 二元分類(Two-Class)
1. 威斯康辛乳癌資料集(Breast Cancer Wisconsin)  
	任務：根據腫瘤的各種醫學影像特徵，判斷其為良性(benign)還是惡性(malignant)  
	此分類的資料非常乾淨、特徵都是數值、沒有遺失值、兩個類別的樣本數也相當平衡  
	約569筆資料，30個數值特徵  
	(在Python scikit-learn中可直接載入：from sklearn.datasets import load_breast_cancer)  

2. 鈔票鑑定資料集
	任務：根據從鈔票圖片中提取的4種特徵，判斷鈔票是真鈔還是偽鈔  
	這同樣是一個非常乾淨、簡單的資料集  
	特徵數量少，可以快速地進行實驗和比較   
	資料量不大不小，很適合跑完整的交叉驗證  
	約1,372筆資料，4個數值特徵  
	UCI連結：https://archive.ics.uci.edu/dataset/267/banknote+authentication  
	

### 多類別分類(Multi-Class)
1. 手寫數字資料集(Digits Dataset)  
	任務：辨識8x8像素的手寫數字圖片，從0到9共10個類別  
	這是一個經典的多類別分類問題，比Iris資料集更有挑戰性，但又不像MNIST那麼大  
	特徵已經處理成64個像素值，可以直接使用  
	約1,797筆資料，64個數值特徵，10個類別  
	(在Python scikit-learn中可直接載入：from sklearn.datasets import load_digits)  

2. 乾豆資料集(Dry Bean Dataset)  
	任務：根據豆子的16種外觀特徵（如面積、周長、長寬比等），將其分類為7種不同的豆子品種   
	這是一個比較新的資料集，資料量比前幾個都大，類別也較多，能更好地測試分類器在更複雜問題上的表現  
	所有特徵都是數值且非常乾淨  
	特性：約13,611筆資料，16個數值特徵7個類別  
	UCI連結：https://archive.ics.uci.edu/dataset/602/dry+bean+dataset  


### 程式碼架構建議
* main.py
	主執行檔，用來讀取資料、呼叫實驗流程  

* classifiers.py
	封裝三個分類器，提供統一的train和test介面  
	需要輸出符合作業格是要求的：predicted class + discriminant function values

* evaluation.py
	放置計算混淆矩陣、繪製ROC曲線等評估用的函式  
	
* utils.py
	放置讀取資料等輔助函式  


### 資料預處理：標準化(Standardization)
SVM和KNN的運作原理都和「距離計算」有關  
如果特徵資料尺度（scale）差異很大那麼使度大的特徵會在距離計算中佔據主導地位，導致模型效果不佳  
因此此處對全部的資料都進行標準化  
注意事項：  
為了避免資料洩漏 (Data Leakage)，標準化應該在交叉驗證的迴圈內部進行，只對當前的訓練集做fit_transform，然後用同一個scaler對測試集做transform  
使用scikit-learn的Pipeline可以效率的完成這件事  



### 超參數實驗(Hyperparameter Experiments)
基於選擇的三個分類器，挑選重要的超參數進行實驗與比較：
* SVM
	* C (懲罰參數)
		嘗試C=0.1, 1, 10 
	* kernel(核心函式)
		比較'linear'(線性)和'rbf'(非線性)的效果

* Random Forest
	* n_estimators (決策樹的數量)
		嘗試n_estimators=50, 100, 200  

* KNN
	* n_neighbors (鄰居的數量, k值)
		嘗試n_neighbors=3, 5, 7 



### 驗證與評估
* 對所有實驗統一使用K=5的交叉驗證  

* 對於4個資料集中的每一個
	1. 計算並展示使用的每個分類器的混淆矩陣，並使用熱力圖來呈現（使用seaborn函式庫的heatmap）  
	2. 記錄並比較它們的Accuracy, Precision, Recall, F1-Score的平均值  
	3. 為每個資料集找到各個分類器的最佳模型後，用長條圖來比較它們的最終表現（例如比較三者的最佳AUC分數或 F1-Score）
	4. 每個分類器在各資料集的ROC-AUC bar chart
	
* 對於2個二元分類資料集
	1. 繪製三種分類器的ROC曲線（畫在同一張圖上方便比較）
	2. 計算並比較它們的AUC分數
	
* 完成上述後，需評估每一個資料集在使用某個分類器進行分類時的表現（如此處有4個資料集、3個分類器，需要有4*3=12個評估）

* 總結：對各個分類器進行總結，評估該分類器更適合哪那些場景。當某個資料集在特定分類器的表現特別突出時，嘗試深入分析

* 結果彙整表格：最終生成一張12組結果的比較，選擇各個模型在不同參數下在各資料集中表現最好的分數進行呈現










